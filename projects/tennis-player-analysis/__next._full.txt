1:"$Sreact.fragment"
2:I[55672,["/_next/static/chunks/1c8935cb71d5ebcf.js"],"default"]
3:I[39756,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
4:I[37457,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"default"]
6:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
7:"$Sreact.suspense"
9:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"ViewportBoundary"]
b:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"MetadataBoundary"]
d:I[68027,[],"default"]
:HL["/_next/static/chunks/638b318308662e2f.css","style"]
:HL["/_next/static/media/03fc1b4a8d284b5e-s.p.af4fcd24.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/1e2b70bb24fd69b4.p.870d0e00.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/248e1dc0efc99276-s.p.8a6b2436.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/8c2eb9ceedecfc8e-s.p.21935807.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"hpq7f_F-I4gD8yKufEBGu","c":["","projects","tennis-player-analysis",""],"q":"","i":false,"f":[[["",{"children":["projects",{"children":[["slug","tennis-player-analysis","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/638b318308662e2f.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/1c8935cb71d5ebcf.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable ibm_plex_sans_d383544b-module__P3SOZq__variable lora_1ae38320-module__0WfQHW__variable inter_fe8b9d92-module__LINzvG__variable merriweather_620cbed2-module__e3WnIq__variable cascadia_mono_a8beebe6-module__cn05aq__variable antialiased bg-white text-gray-900 min-h-screen font-sans","children":["$","div",null,{"className":"max-w-6xl mx-auto px-6","children":[["$","$L2",null,{}],["$","main",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L5",[["$","script","script-0",{"src":"/_next/static/chunks/71168b994b248471.js","async":true,"nonce":"$undefined"}]],["$","$L6",null,{"children":["$","$7",null,{"name":"Next.MetadataOutlet","children":"$@8"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L9",null,{"children":"$@a"}],["$","div",null,{"hidden":true,"children":["$","$Lb",null,{"children":["$","$7",null,{"name":"Next.Metadata","children":"$@c"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$d",[]],"s":false,"S":true}
e:I[91397,["/_next/static/chunks/1c8935cb71d5ebcf.js","/_next/static/chunks/71168b994b248471.js"],"default"]
f:Tbbf,# Tennis Serve Extraction and Analysis 

<!-- ![Demo](bin/project_demonstration.gif) -->
<center>
<img src="https://raw.githubusercontent.com/imrnh/tennis_player_analysis/main/bin/presentation/project_demonstration.gif" alt="Demo" height="400">

or watch the video here: https://youtu.be/53Lz9B7wAYQ

</center>



### Extracted the following informations:

From a tennis gameplay video, 

1) Identify a serve and extract the type for each of the serves (Flat / Kick / Slice) 
2) Determine the success of the Serve (in/out/let)
3) Calculate *toss height*, *toss position*, *hit height*, *serve speed* and *player speed*.

# Worflow
1) Firstly, a ConvNet network was trained to extract 14 marker points in the court. These 14 marker points are then connected as following to build the board:
    0 → 4, 4 → 6, 6 → 1, 0 → 2, 1 → 3, 4 → 8, 2 → 5, 8 → 10, 10 → 5, 9 → 11, 6 → 9, 11 → 7, 12 → 13, 5 → 7, 7 → 3, 10 → 13, 13 → 11, 8 → 12, 12 → 9

    <br>
    <center><img src="https://raw.githubusercontent.com/imrnh/tennis_player_analysis/main/bin/presentation/picture_court_processed.png" width="700"></center>
    <br><br>
2) Another YOLO model detects the players, the ball and the net of the game. Net detection is nedded to identify if a server is **Let** or not. **Mediapipe** is used to identify the player pose for each detected players. Also, a *face recognizer ConvNet* has been trained to identify players of both side. 

3) These players will be tracked throughout the match even if they switch side or camera moves to the audience and return back.

4) For understanding serve type, a **ConvNet + Transformer** architecture has been used. Another ConvNet network (Gate Logic) tracks ball and player trajectory to understand when a serve started and when a serve finished. This ensure that we keep track of only the current recordings of a serve and previous serve data cannot intervine the output of the present serve data. Therefore, it is a gated Transformer architecture where a custom gate is used with CNN. This is the complete architecture of the game analysis module made with 2 CNN and 1 transformer network.

<center>
<img src="https://github.com/imrnh/tennis_player_analysis/raw/main/bin/presentation/tennis_game_analysis_module.png" width="90%">
<br>Fig: Game analysis module 
</center>



# Infernece
You can either run the whole pipeline to get the stats of a player. Or you can separetely run each of the step in workflow. We will start with seperate workflow first. If you need to run the whole pipeline at once, please check the bottom of the file.


The segmented video is used to train the model and then inference from it. This helps the model to only focus on relevant information and hence drastically reduces the data requirements. The following comamnd generates the segmented output.

```bash
!python make_segmentation.py \
  --input bin/data/inference/tennis_play_record_1_short_v2.mp4 \
  --output bin/data/output_segmented_video.avi
```5:["$","$Le",null,{"content":"$f"}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
10:I[27201,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"IconMark"]
c:[["$","title","0",{"children":"Imran Hossen | Portfolio"}],["$","meta","1",{"name":"description","content":"Developer & Designer Portfolio"}],["$","link","2",{"rel":"icon","href":"/favicon.ico?favicon.630925ba.ico","sizes":"115x115","type":"image/x-icon"}],["$","$L10","3",{}]]
8:null
